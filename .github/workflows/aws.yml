name: Build and upload to S3

on: push
      
jobs:
  run-and-upload:
    name: Build and upload to S3
    
    runs-on: self-hosted

    strategy:
      matrix:
        mode: [DEBUG, RELEASE]
        
    env:
      PYTHON_VERSION: '3.12'
      PROJECT_NAME: ${{ github.event.repository.name }}
      MODE: ${{ matrix.mode }}
      UPLOAD_REPO_NAME: ${{ github.event.repository.name }}/${{ github.run_number }}/${{ matrix.mode }}
      BUILD_REPO_NAME: ${{ matrix.mode }}
      AWS_BUCKET_NAME: ${{ secrets.AWS_BUCKET_NAME }}
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_REGION: ${{ secrets.AWS_REGION }}
      PREFIX: ''
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Build ${{ env.PROJECT_NAME }} ${{ env.MODE }}
        run: |
          python build.py ${{ env.BUILD_REPO_NAME }} ${{ env.MODE }}
      
      - name: Upload to S3
        if: success()
        run: |
          zip -r -j ${{ env.BUILD_REPO_NAME }}.zip ${{ env.BUILD_REPO_NAME }}/*
          aws s3 cp ${{ env.BUILD_REPO_NAME }}.zip s3://${{ env.AWS_BUCKET_NAME }}/${{ env.UPLOAD_REPO_NAME }}.zip --region ${{ env.AWS_REGION }}
          
      - name: Cleaning up
        run: |
          rm -r -f ${{ env.BUILD_REPO_NAME }}
          rm -f ${{ env.BUILD_REPO_NAME }}.zip

      - name: Clean old builds from S3
        if: success()
        run: |
          folder_list=$(aws s3api list-objects-v2 --bucket ${{ env.AWS_BUCKET_NAME }} --prefix ${{ env.PROJECT_NAME }}/ --delimiter '/' --query 'CommonPrefixes[*].Prefix' --output text)
          folders_with_dates=$(for folder in $folder_list; do echo "$(aws s3 ls s3://${{ env.AWS_BUCKET_NAME }}/$folder --recursive | sort | tail -n 1) $folder"; done)
          sorted_folders=$(echo "$folders_with_dates" | sort | awk '{print $NF}')
          folder_array=($sorted_folders)

          if [ ${#folder_array[@]} -le 2 ]; then
            exit 0
          fi
          
          folders_to_delete=("${folder_array[@]:0:${#folder_array[@]}-2}")
          
          for folder in "${folders_to_delete[@]}"; do
            aws s3 rm "s3://${{ env.AWS_BUCKET_NAME }}/$folder" --recursive
          done
