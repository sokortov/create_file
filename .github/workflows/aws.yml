name: Build and upload to S3

on: push
      
jobs:
  run-and-upload:
    name: Build and upload to S3
    
    runs-on: self-hosted

    strategy:
      matrix:
        mode: [DEBUG, RELEASE]
        
    env:
      PYTHON_VERSION: '3.12'
      PROJECT_NAME: ${{ github.event.repository.name }}
      MODE: ${{ matrix.mode }}
      BUILD_REPO_NAME: ${{ github.event.repository.name }}/${{ github.sha }}/${{ matrix.mode }}
      AWS_BUCKET_NAME: ${{ secrets.AWS_BUCKET_NAME }}
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_REGION: ${{ secrets.AWS_REGION }}
      PREFIX: ''
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Build ${{ env.PROJECT_NAME }} ${{ env.MODE }}
        run: |
          python build.py ${{ env.BUILD_REPO_NAME }} ${{ env.MODE }}
          
      - name: Get commit message
        id: get_commit
        run: echo "COMMIT_MESSAGE=$(git log -1 --pretty=%B)" >> $GITHUB_ENV
      
      - name: Upload to S3
        if: success()
        run: |
          zip -r ${{ env.BUILD_REPO_NAME }}.zip -j ${{ env.BUILD_REPO_NAME }}
          aws s3 cp ${{ env.BUILD_REPO_NAME }}.zip s3://${{ env.AWS_BUCKET_NAME }}/${{ env.COMMIT_MESSAGE }}/${{ env.BUILD_REPO_NAME }}.zip --region ${{ env.AWS_REGION }}
           

      - name: List and delete old folders in S3 bucket
        run: |
          # Получаем список всех объектов в бакете
          echo "Получаем список всех объектов в бакете:"
          aws s3 ls s3://${{ env.AWS_BUCKET_NAME }}/ --recursive
          
          # Сохраняем список всех объектов в файл
          aws s3 ls s3://${{ env.AWS_BUCKET_NAME }}/ --recursive > objects.txt
          
          # Отладочный вывод для проверки содержимого
          echo "Содержимое файла objects.txt:"
          cat objects.txt

          # Получаем список уникальных папок
          awk '{print $2}' objects.txt | sort | uniq | grep -oE '[0-9]+' > folders.txt
          
          # Отладочный вывод для проверки содержимого
          echo "Список папок:"
          cat folders.txt

          # Подсчитываем количество уникальных папок
          TOTAL_FOLDERS=$(cat folders.txt | wc -l)
          echo "Общее количество папок: $TOTAL_FOLDERS"

          # Сколько папок нужно удалить
          DELETE_COUNT=$(($TOTAL_FOLDERS - 5))
          echo "Папок для удаления: $DELETE_COUNT"

          if [ $DELETE_COUNT -gt 0 ]; then
            # Получаем папки, которые нужно удалить
            FOLDERS_TO_DELETE=$(cat folders.txt | head -n $DELETE_COUNT)
            
            # Отладочный вывод для проверки папок на удаление
            echo "Папки для удаления:"
            echo "$FOLDERS_TO_DELETE"

            # Удаляем старые папки
            for FOLDER in $FOLDERS_TO_DELETE; do
              echo "Удаление папки: $FOLDER"
              aws s3 rm s3://${{ env.AWS_BUCKET_NAME }}/$FOLDER --recursive
            done
          else
            echo "Нет папок для удаления."
          fi
          
        
      - name: Cleaning up
        run: |
          rm -r -f ${{ env.BUILD_REPO_NAME }}
